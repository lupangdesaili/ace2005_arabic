{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from transformers import BertTokenizer, BertForTokenClassification, BertModel\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "model_name = \"asafaya/bert-base-arabic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_bert(name):   \n",
    "    tokenizer = BertTokenizer.from_pretrained(name)\n",
    "    model = BertModel.from_pretrained(name)\n",
    "    return tokenizer, model\n",
    "\n",
    "def init_device():\n",
    "    if torch.cuda.is_available():       \n",
    "        device = torch.device(\"cuda:0\")\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "def trigger_data_further_process(input):\n",
    "    notes = input['notes']\n",
    "    input_notes = []\n",
    "    for i, note in enumerate(notes):\n",
    "        if i == 0:\n",
    "            if \"T\" in notes[i]:\n",
    "                input_notes.append(\"B-T\")\n",
    "            else:\n",
    "                input_notes.append(\"O\")\n",
    "        else:\n",
    "            if \"T\" in notes[i]:\n",
    "                if \"T\" not in notes[i-1]:\n",
    "                    input_notes.append(\"B-T\")\n",
    "                else:\n",
    "                    input_notes.append(\"I-T\")\n",
    "            else:\n",
    "                input_notes.append(\"O\")\n",
    "    return input_notes\n",
    "\n",
    "class pad_collate:\n",
    "    def __init__(self,max_length):\n",
    "        self.max_length = max_length\n",
    "    def padding(self,batch):\n",
    "        ids = [sample[0] for sample in batch]\n",
    "        ids = pad_sequence(ids, batch_first=True)[:,:self.max_length]\n",
    "        labels = [sample[-1] for sample in batch]\n",
    "        labels = pad_sequence(labels, batch_first=True)[:,:self.max_length]\n",
    "        masks = torch.zeros(size = ids.size())\n",
    "        masks[ids > 0] = 1\n",
    "        return ids, labels, masks\n",
    "    def __call__(self,batch):\n",
    "        return self.padding(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ace_dataset(Dataset):\n",
    "    def __init__(self, datas, max_length, filter = False):\n",
    "        if filter:\n",
    "            datas = [x for x in datas if len(x['tokens']) <= max_length - 2]\n",
    "        tokens = [x['tokens'] for x in datas]\n",
    "        self.ids = [[2] + tokenizer.convert_tokens_to_ids(seq) + [3] for seq in tokens]\n",
    "        labels = [trigger_data_further_process(x) for x in datas]\n",
    "        self.map = {\"O\":0,\"B-T\":1,\"I-T\":2}\n",
    "        self.labels = [[0]+[self.map[x] for x in y]+[0] for y in labels]\n",
    "        self.len = len(self.ids)\n",
    "        self.max_length = max_length\n",
    "        self.tokens = tokens\n",
    "        self.datas = datas\n",
    "    def __getitem__(self,index):\n",
    "        if type(index) == slice:\n",
    "            id_torch = [torch.tensor(x) for x in self.ids[index]]\n",
    "            label_torch  = [torch.tensor(x) for x in self.labels[index]]\n",
    "            return pad_sequence(id_torch, batch_first = True)[:,:self.max_length],pad_sequence(label_torch, batch_first = True)[:,:self.max_length]\n",
    "        else:\n",
    "            id_torch = torch.tensor(self.ids[index])\n",
    "            label_torch  = torch.tensor(self.labels[index])\n",
    "            return id_torch[:self.max_length],label_torch[:self.max_length]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "def init_dataset(max_length,tokenizer):\n",
    "    test_files, dev_files, train_files = get_data_paths(\"ace_2005/data/Arabic\")\n",
    "    train_processor = ara_ace_master(train_files, tokenizer)\n",
    "    dev_processor = ara_ace_master(dev_files, tokenizer)\n",
    "    test_processor = ara_ace_master(test_files, tokenizer)\n",
    "    train_processor.extract_trigger_data()\n",
    "    train_datas = [y for x in train_processor.trigger_datas for y in x]\n",
    "    dev_processor.extract_trigger_data()\n",
    "    dev_datas = [y for x in dev_processor.trigger_datas for y in x]\n",
    "    test_processor.extract_trigger_data()\n",
    "    test_datas = [y for x in test_processor.trigger_datas for y in x]\n",
    "    train_dataset =  ace_dataset(train_datas,max_length,filter = True)\n",
    "    dev_dataset = ace_dataset(dev_datas,max_length,filter = True)\n",
    "    test_dataset  = ace_dataset(test_datas,max_length,filter = True)\n",
    "    return train_dataset, dev_dataset, test_dataset\n",
    "\n",
    "def init_dataloader(train_dataset, dev_dataset, test_dataset, batch_size, max_length):\n",
    "    #func = lambda x:(pad_sequence([torch.tensor(seq) for seq in x[0]],batch_first=True)[:,:max_length],pad_sequence([torch.tensor(seq) for seq in x[1]],batch_first=True)[:,:max_length])\n",
    "    train_loader = DataLoader(train_dataset,batch_size = batch_size, shuffle = True, collate_fn = pad_collate(max_length))\n",
    "    dev_loader= DataLoader(dev_dataset,batch_size = 32, shuffle = True, collate_fn = pad_collate(max_length))\n",
    "    test_loader = DataLoader(test_dataset,batch_size = 32, shuffle = True, collate_fn = pad_collate(max_length))\n",
    "    return train_loader, dev_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class focal_loss(nn.Module):\n",
    "    def __init__(self, num_classes, alpha=0.25, gamma=2 , size_average=True):\n",
    "        super(focal_loss,self).__init__()\n",
    "        self.size_average = size_average\n",
    "        if isinstance(alpha,list):\n",
    "            assert len(alpha)==num_classes   \n",
    "            self.alpha = torch.Tensor(alpha)\n",
    "        else:\n",
    "            assert alpha<1  \n",
    "            self.alpha = torch.zeros(num_classes)\n",
    "            self.alpha[0] += alpha\n",
    "            self.alpha[1:] += (1-alpha)\n",
    "        self.gamma = gamma\n",
    "    def forward(self, preds, labels):\n",
    "        # assert preds.dim()==2 and labels.dim()==1\n",
    "        preds = preds.view(-1,preds.size(-1))\n",
    "        self.alpha = self.alpha.to(preds.device)\n",
    "        preds_softmax = preds\n",
    "        #preds_softmax = F.softmax(preds, dim=1) \n",
    "        preds_logsoft = torch.log(preds_softmax)\n",
    "        #focal_loss func, Loss = -α(1-yi)**γ *ce_loss(xi,yi)\n",
    "        preds_softmax = preds_softmax.gather(1,labels.view(-1,1)) \n",
    "        preds_logsoft = preds_logsoft.gather(1,labels.view(-1,1))\n",
    "        self.alpha = self.alpha.gather(0,labels.view(-1))\n",
    "        # torch.pow((1-preds_softmax), self.gamma) 为focal loss中 (1-pt)**γ\n",
    "        loss = -torch.mul(torch.pow((1-preds_softmax), self.gamma), preds_logsoft) \n",
    "        loss = torch.mul(self.alpha, loss.t())\n",
    "        if self.size_average:\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            loss = loss.sum()\n",
    "        return loss\n",
    "\n",
    "class TokenClassification(nn.Module):\n",
    "    def __init__(self,bert_model,num_label,device):\n",
    "        super(TokenClassification, self).__init__()\n",
    "        self.model = bert_model\n",
    "        self.model = self.model.to(device)\n",
    "        self.hidden_size = model.config.hidden_size\n",
    "        self.num_label = num_label\n",
    "        self.fc_logits = nn.Linear(self.hidden_size, self.num_label, bias = True)\n",
    "        self.device = device\n",
    "        self.loss_func = focal_loss(self.num_label)\n",
    "    def forward(self,input_ids, attention_mask, labels):\n",
    "        bert_output = self.model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        hidden_state = bert_output.last_hidden_state\n",
    "        trigger_logits = self.fc_logits(hidden_state)\n",
    "        trigger_softmax = F.softmax(trigger_logits, dim = -1)\n",
    "        loss = self.loss_func(trigger_softmax, labels)\n",
    "        return trigger_softmax, loss\n",
    "    def inferer(self,input):\n",
    "        self.eval()\n",
    "        input_tokens = tokenizer.tokenize(input)\n",
    "        input_ids = tokenizer.encode(input,return_tensors=\"pt\")\n",
    "        input_ids = input_ids.to(self.device)\n",
    "        #input_ids = input_ids.to(device)\n",
    "        bert_output = self.model(input_ids = input_ids, attention_mask = None)\n",
    "        #bert_output = trainer.model.model(input_ids = input_ids, attention_mask = None)\n",
    "        hidden_state = bert_output.last_hidden_state\n",
    "        trigger_logits = self.fc_logits(hidden_state)\n",
    "        #trigger_logits = trainer.model.fc_logits(hidden_state)\n",
    "        trigger_hat = trigger_logits.cpu().detach().argmax(dim = -1)\n",
    "        trigger_hat = trigger_hat.squeeze()\n",
    "        trigger_hat = trigger_hat[1:-1]\n",
    "        return input_tokens,trigger_hat\n",
    "\n",
    "class main_trainer:\n",
    "    def __init__(self,model,lr,device,num_label):\n",
    "        self.model = TokenClassification(model,num_label,device)\n",
    "        self.lr = lr\n",
    "        self.optim = Adam(self.model.parameters(),lr = self.lr)\n",
    "        self.device = device\n",
    "        self.model = self.model.to(self.device)\n",
    "    def train(self,dataloader,epochs,eval_dataset):\n",
    "        epoch_bar = tqdm(total = epochs, desc = \"epoch\")\n",
    "        self.hist_train = []\n",
    "        self.hist_eval = []\n",
    "        for epoch in range(epochs):\n",
    "            epoch_bar.set_postfix(epoch = epoch)\n",
    "            train_bar = tqdm(total = len(dataloader),desc=\"train\")\n",
    "            epoch_pred = []\n",
    "            epoch_true = []\n",
    "            running_loss = 0\n",
    "            for i, (ids, labels, masks) in enumerate(dataloader):\n",
    "                self.model.train()\n",
    "                self.optim.zero_grad()\n",
    "                batch_size = ids.size()[0]\n",
    "                ids = ids.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                masks = masks.to(self.device)\n",
    "                trigger_softmax, loss = self.model(input_ids = ids, attention_mask = masks, labels = labels)\n",
    "                #except:\n",
    "                #    print(ids.shape,masks.shape,labels.shape)\n",
    "                #    continue\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "                y_pred = torch.argmax(trigger_softmax.cpu().detach(), dim = -1)[masks == 1]\n",
    "                labels = labels.cpu().detach()\n",
    "                y = labels[masks == 1]\n",
    "                if len(set(y_pred.tolist())) == 1:\n",
    "                    wrong = \"error\"\n",
    "                else:\n",
    "                    wrong = \"none\"\n",
    "                epoch_pred += y_pred\n",
    "                epoch_true += y\n",
    "                epoch_acc = accuracy_score(epoch_true, epoch_pred)\n",
    "                epoch_f1 = f1_score(epoch_true, epoch_pred,average='micro')\n",
    "                train_bar.set_postfix(\n",
    "                                    wrong = wrong,\n",
    "                                    acc = epoch_acc,\n",
    "                                    f1 = epoch_f1,\n",
    "                                    loss = loss.item())\n",
    "                running_loss += (loss.item() - running_loss)/(i+1)\n",
    "                train_bar.update()\n",
    "            train_bar.n = 0\n",
    "            epoch_bar.update()\n",
    "            self.hist_train.append((epoch_acc, epoch_f1, running_loss))\n",
    "            eval_acc, eval_f1, eval_loss = self.eval(eval_dataset)\n",
    "            self.hist_eval.append((eval_acc, eval_f1, eval_loss))\n",
    "            epoch_bar.set_postfix(eval_acc = eval_acc, eval_f1 = eval_f1)\n",
    "    def eval(self,dataset):\n",
    "        self.model.eval()\n",
    "        pred = []\n",
    "        true = []\n",
    "        running_loss = 0\n",
    "        bar = tqdm(total = len(dataset), desc = \"evaluating\")\n",
    "        for i, (ids, labels) in enumerate(dataset):\n",
    "            ids = ids.to(self.device).unsqueeze(0)\n",
    "            labels = labels.to(self.device).unsqueeze(0)\n",
    "            trigger_softmax, loss = self.model(input_ids = ids, attention_mask= None,labels = labels)\n",
    "            trigger_softmax = trigger_softmax.cpu().detach()\n",
    "            y_pred = torch.argmax(trigger_softmax, dim = -1)\n",
    "            y_pred = y_pred.squeeze()\n",
    "            labels = labels.cpu().detach()\n",
    "            labels = labels.squeeze()\n",
    "            if len(set(y_pred.tolist())) == 1:\n",
    "                error = \"error\"\n",
    "            else:\n",
    "                error = \"none\"\n",
    "            pred += y_pred\n",
    "            true += labels\n",
    "            acc = accuracy_score(true, pred)\n",
    "            f1 = f1_score(true, pred, average='micro')\n",
    "            running_loss = (loss.item() - running_loss)/(i+1)\n",
    "            bar.set_postfix(error = error, acc = acc, f1 = f1, loss = running_loss)\n",
    "            bar.update()\n",
    "        return acc, f1, running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_check(data):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(data[0])\n",
    "    sent = \" \".join(x for x in tokens)\n",
    "    ids = data[1]\n",
    "    trigger = []\n",
    "    for i,(token,id) in enumerate(zip(tokens,ids)):\n",
    "        if id == 1:\n",
    "            head = tokens[i]\n",
    "            trigger.append(head)\n",
    "        if id == 2:\n",
    "            trigger[-1] += \" \"+tokens[i]\n",
    "    trigger_text = \"|\".join(x for x in trigger)\n",
    "    print(f\"sentence = {sent},triggers = {trigger_text}\")\n",
    "\n",
    "def show_length_distribution(dataset):\n",
    "    lengths = []\n",
    "    for data in dataset:\n",
    "        length = len(data[0])\n",
    "        lengths.append(length)\n",
    "    pd.DataFrame(lengths).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "  5%|▍         | 16/322 [00:00<00:01, 156.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322/322 [00:02<00:00, 153.64it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 173.49it/s]\n",
      "100%|██████████| 41/41 [00:00<00:00, 159.52it/s]\n",
      "322it [00:05, 64.37it/s, wrong_data=279]\n",
      "40it [00:00, 80.93it/s, wrong_data=36]\n",
      "41it [00:00, 62.94it/s, wrong_data=51]\n"
     ]
    }
   ],
   "source": [
    "ace2005_path = \"ace_2005/data/Arabic\"\n",
    "model_name = \"asafaya/bert-base-arabic\"\n",
    "max_length = 100\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "epoch = 30\n",
    "tokenizer, model = init_bert(model_name)\n",
    "device = init_device()\n",
    "train_set, dev_set, test_set = init_dataset(max_length = max_length, tokenizer = tokenizer)\n",
    "show_length_distribution(train_set)\n",
    "train_loader, dev_loader, test_loader = init_dataloader(train_set, dev_set, test_set, batch_size = batch_size, max_length = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_length_distribution(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 1909, 3649, 3]"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"قال سعيد\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracter = TokenClassification(model,3,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence = [CLS] وفي قطاع غزة ، تعرضت عربة عسكرية لاطلاق نار من دون وقوع ضحايا بالقرب من مستوطن ##ة نت ##سار ##يم ، بحسب المصدر نفسه . [SEP],triggers = لاطلاق\n"
     ]
    }
   ],
   "source": [
    "settings = {\"model\":model,\"lr\":lr,\"device\":device,\"num_label\":3}\n",
    "#model,lr,device,num_label\n",
    "trainer = main_trainer(**settings)\n",
    "trainer.train(train_loader,20,dev_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.inferer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"تواصل حركة طالبان الزحف نحو العاصمة كابل، السبت، مع سقوط الولايات الأفغانية واحدة تلو الأخرى، وبعضها دون قتال، حيث باتت الحركة تسيطر على 14 من عواصم الأقاليم الأفغانية البالغ عددها 34 منذ السادس من أغسطس.\"\n",
    "trainer.model.inferer(input,tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}